
\section{Abstract}

Using adaptive, machine learning (ML)-based classifiers, electroencephalography (EEG) signals have been used to build applications ranging from mind-controlled keyboards to prosthetic arms and hands. Unfortunately, these applications require elaborate scanning caps, and the data thse caps produce are large in memory and computationally expensive to process. Do we really need lossless data to achieve acceptable BCI? Can we compress EEG data without serious detriment to classifier performance? If so, what do we gain in computational cost? In this study, we seek the optimal compromise between compression, classifier accuracy and computational expense. We use recordings of mental tasks from a single EEG electrode and train a linear support vector classifier (SVC) to distinguish between task pairs within subject. ``by compressing data to 1/x their original size using a logarithmic binning method, we find an \ital{increase} in accuracy from a to b, and fail to find evidence of significant degredation in performance at up to 1/y of the data's original size.''  now that it scales in time too:``this compression technique appears to preserve classifier accuracy even among one- and two-second subsets of the original data.'' now that its fast as fck:``this compression is met with a 10^m increase in classifier speed over uncompressed data.''  Our findings suggest that compression techniques could enable ML-based EEG in the cloud, as compression minimizes data throughput, or on lightweight, embeded processors.